<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Evaluating QA: Metrics, Predictions, and the Null Response | NLP for Question Answering</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Evaluating QA: Metrics, Predictions, and the Null Response" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A deep dive into computing QA predictions and when to tell BERT to zip it!" />
<meta property="og:description" content="A deep dive into computing QA predictions and when to tell BERT to zip it!" />
<link rel="canonical" href="https://qa.fastforwardlabs.com/hidden/" />
<meta property="og:url" content="https://qa.fastforwardlabs.com/hidden/" />
<meta property="og:site_name" content="NLP for Question Answering" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-09T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"A deep dive into computing QA predictions and when to tell BERT to zip it!","@type":"BlogPosting","headline":"Evaluating QA: Metrics, Predictions, and the Null Response","dateModified":"2020-06-09T00:00:00-05:00","datePublished":"2020-06-09T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://qa.fastforwardlabs.com/hidden/"},"url":"https://qa.fastforwardlabs.com/hidden/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://qa.fastforwardlabs.com/feed.xml" title="NLP for Question Answering" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-157475426-3','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Evaluating QA: Metrics, Predictions, and the Null Response | NLP for Question Answering</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Evaluating QA: Metrics, Predictions, and the Null Response" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A deep dive into computing QA predictions and when to tell BERT to zip it!" />
<meta property="og:description" content="A deep dive into computing QA predictions and when to tell BERT to zip it!" />
<link rel="canonical" href="https://qa.fastforwardlabs.com/hidden/" />
<meta property="og:url" content="https://qa.fastforwardlabs.com/hidden/" />
<meta property="og:site_name" content="NLP for Question Answering" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-09T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"A deep dive into computing QA predictions and when to tell BERT to zip it!","@type":"BlogPosting","headline":"Evaluating QA: Metrics, Predictions, and the Null Response","dateModified":"2020-06-09T00:00:00-05:00","datePublished":"2020-06-09T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://qa.fastforwardlabs.com/hidden/"},"url":"https://qa.fastforwardlabs.com/hidden/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://qa.fastforwardlabs.com/feed.xml" title="NLP for Question Answering" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-157475426-3','auto');ga('require','displayfeatures');ga('send','pageview');</script>



<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">NLP for Question Answering</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Us</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Evaluating QA: Metrics, Predictions, and the Null Response</h1><p class="page-description">A deep dive into computing QA predictions and when to tell BERT to zip it!</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-09T00:00:00-05:00" itemprop="datePublished">
        Jun 9, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      33 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#null threshold">null threshold</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#bert">bert</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#distilbert">distilbert</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#exact match">exact match</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#F1">F1</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#robust predictions">robust predictions</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/fastforwardlabs/ff14_blog/tree/master/_notebooks/2020-06-09-Evaluating_BERT_on_SQuAD.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/fastforwardlabs/ff14_blog/master?filepath=_notebooks%2F2020-06-09-Evaluating_BERT_on_SQuAD.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/fastforwardlabs/ff14_blog/blob/master/_notebooks/2020-06-09-Evaluating_BERT_on_SQuAD.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h3"><a href="#Prerequisites">Prerequisites </a></li>
<li class="toc-entry toc-h1"><a href="#Answering-questions-is-complicated">Answering questions is complicated </a></li>
<li class="toc-entry toc-h1"><a href="#The-SQuAD2.0-dev-set">The SQuAD2.0 dev set </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Load-the-dev-set-using-HF-data-processors">Load the dev set using HF data processors </a>
<ul>
<li class="toc-entry toc-h4"><a href="#A-positive-example">A positive example </a></li>
<li class="toc-entry toc-h4"><a href="#A-negative-example">A negative example </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Metrics-for-QA">Metrics for QA </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Exact-Match">Exact Match </a></li>
<li class="toc-entry toc-h3"><a href="#F1">F1 </a></li>
<li class="toc-entry toc-h3"><a href="#Load-a-Transformer-model-fine-tuned-on-SQuAD-2.0">Load a Transformer model fine-tuned on SQuAD 2.0 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Evaluating-a-model-on-the-SQuAD2.0-dev-set-with-HF">Evaluating a model on the SQuAD2.0 dev set with HF </a>
<ul>
<li class="toc-entry toc-h3"><a href="#[Optional/highly-technical]-Computing-predictions">[Optional/highly technical] Computing predictions </a></li>
<li class="toc-entry toc-h3"><a href="#Using-the-null-threshold">Using the null threshold </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Putting-it-all-together">Putting it all together </a></li>
<li class="toc-entry toc-h1"><a href="#Final-Thoughts">Final Thoughts </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-09-Evaluating_BERT_on_SQuAD.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In our last post, <a href="https://qa.fastforwardlabs.com/pytorch/hugging%20face/wikipedia/bert/transformers/2020/05/19/Getting_Started_with_QA.html">Building a QA System with BERT on Wikipedia</a>, we used the HuggingFace framework to train BERT on the SQuAD2.0 dataset and built a simple QA system on top of the Wikipedia search engine. This time, we'll look at how to assess the quality of a BERT-like model for Question Answering. We'll cover what metrics are used to quantify quality, how to evaluate your model using the Hugging Face framework, and the importance of the "null response" -- questions that don't have answers -- for both improved performance and more realistic QA output.  By the end of this post we'll implement a more robust answering method for our QA system.</p>
<p>Throughout this post we'll be using a distilBERT model fine-tuned on SQuAD2.0 by a member of the NLP community; this model can be found <a href="https://huggingface.co/twmkn9/distilbert-base-uncased-squad2">here</a> in the HF repository. Additionally, much of the code in this post is inspired by the HF <code>squad_metrics.py</code> script.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Prerequisites">
<a class="anchor" href="#Prerequisites" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prerequisites<a class="anchor-link" href="#Prerequisites"> </a>
</h3>
<ul>
<li>A basic understanding of Transformers and PyTorch</li>
<li>A basic understanding of Transformer outputs (logits) and softmax</li>
<li>A Transformer fine-tuned on SQuAD2.0</li>
<li>The SQuAD2.0 dev set</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Answering-questions-is-complicated">
<a class="anchor" href="#Answering-questions-is-complicated" aria-hidden="true"><span class="octicon octicon-link"></span></a>Answering questions is complicated<a class="anchor-link" href="#Answering-questions-is-complicated"> </a>
</h1>
<p>Quantifying the success of answering a question is a tricky task. When you or I ask a question, the correct answer could take multiple forms. For example, in our previous post, BERT answered the question, "Why is the sky blue?" with "Rayleigh scattering" but another answer would be:</p>
<blockquote>
<p>The Earth's atmosphere scatters short-wavelength light more efficiently than that of longer wavelengths. Because its wavelengths are shorter, blue light is more strongly scattered than the longer-wavelength lights, red or green. Hence the result that when looking at the sky away from the direct incident sunlight, the human eye perceives the sky to be blue.</p>
</blockquote>
<p>Both of these passages can be found in the Wikipedia article <a href="https://en.wikipedia.org/wiki/Diffuse_sky_radiation">Diffuse Sky Radiation</a> and both are correct. However, I've also had a model answer with "because its wavelengths are shorter", which is close but not really a correct answer - the sky itself doesn't have a wavelength. This answer is missing too much context to be useful. 
What if we'd asked a question that couldn't be answered by the Diffuse Sky Radiation page? For example: "Could the sky ever be green?" If you read that Wiki article you'll see there probably isn't a sure-fire answer to this question. What should the model do in this case?</p>
<p>How should we judge a model when there are multiple correct answers, even more incorrect answers, and potentially no answer? To properly assess quality we need a labeled set of questions and answers. Let's turn back to the SQuAD dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-SQuAD2.0-dev-set">
<a class="anchor" href="#The-SQuAD2.0-dev-set" aria-hidden="true"><span class="octicon octicon-link"></span></a>The SQuAD2.0 dev set<a class="anchor-link" href="#The-SQuAD2.0-dev-set"> </a>
</h1>
<p>The <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD dataset</a> comes in two flavors: SQuAD1.1 and SQuAD2.0. The latter contains the same questions and answers as the former but also includes additional questions that <em>cannot</em> be answered by the accompanying passage. This is intended to provide a more realistic question answering task. The ability to identify unanswerable questions is much more challenging for Transformer models and it's why we focused on the SQuAD2.0 dataset rather than SQuAD1.1.</p>
<p>SQuAD2.0 consists of over 150k questions, of which more than 35% are unanswerable in relation to their associated passage. Last time we fine-tuned on the train set (130k examples); now we'll focus on the dev set, which contains nearly 12k examples. Only about half of these examples are answerable questions. In the following section we'll look at a couple of these examples to get a feel for them.</p>
<p>(Use the hidden cells below to get set set up, if needed.)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># collapse-hide</span>

<span class="c1"># use this cell to install packages if needed</span>
<span class="o">!</span>pip install torch  torchvision -f https://download.pytorch.org/whl/torch_stable.html
<span class="o">!</span>pip install transformers
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Looking in links: https://download.pytorch.org/whl/torch_stable.html
Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)
Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.4)
Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)
Requirement already satisfied: pillow&gt;=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)
Collecting transformers
  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)
     |████████████████████████████████| 675kB 6.3MB/s 
Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)
Collecting sentencepiece
  Downloading https://files.pythonhosted.org/packages/68/e5/0366f50a00db181f4b7f3bdc408fc7c4177657f5bf45cb799b79fb4ce15c/sentencepiece-0.1.92-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)
     |████████████████████████████████| 1.2MB 17.6MB/s 
Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)
Collecting tokenizers==0.7.0
  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)
     |████████████████████████████████| 3.8MB 40.9MB/s 
Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)
Collecting sacremoses
  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)
     |████████████████████████████████| 890kB 41.9MB/s 
Requirement already satisfied: dataclasses; python_version &lt; "3.7" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (2.9)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (1.24.3)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (2020.4.5.1)
Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging-&gt;transformers) (2.4.7)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging-&gt;transformers) (1.12.0)
Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses-&gt;transformers) (7.1.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses-&gt;transformers) (0.15.1)
Building wheels for collected packages: sacremoses
  Building wheel for sacremoses (setup.py) ... done
  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=51313d3711445a6b374731de96cb090357b694f41b7d4d5883ce1359d8bf610c
  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45
Successfully built sacremoses
Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers
Successfully installed sacremoses-0.0.43 sentencepiece-0.1.92 tokenizers-0.7.0 transformers-2.11.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># collapse-hide</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForQuestionAnswering</span>

<span class="c1"># This is the directory in which we'll store all evaluation output</span>
<span class="n">model_dir</span> <span class="o">=</span> <span class="s2">"models/distilbert/twmkn9_distilbert-base-uncased-squad2/"</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># collapse-hide</span>

<span class="c1"># Download the SQuAD2.0 dev set</span>
<span class="o">!</span>wget -P data/squad/ https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-06-08 20:21:09--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json
Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.109.153, 185.199.111.153, ...
Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4370528 (4.2M) [application/json]
Saving to: ‘data/squad/dev-v2.0.json’

dev-v2.0.json       100%[===================&gt;]   4.17M  --.-KB/s    in 0.1s    

2020-06-08 20:21:10 (33.7 MB/s) - ‘data/squad/dev-v2.0.json’ saved [4370528/4370528]

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-the-dev-set-using-HF-data-processors">
<a class="anchor" href="#Load-the-dev-set-using-HF-data-processors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load the dev set using HF data processors<a class="anchor-link" href="#Load-the-dev-set-using-HF-data-processors"> </a>
</h3>
<p>Hugging Face provide the <a href="https://huggingface.co/transformers/main_classes/processors.html">Processors</a> library for facilitating basic processing tasks with some canonical NLP datasets. The processors can be used for loading datasets and converting their examples to features for direct use in the model. We'll be using the <a href="https://huggingface.co/transformers/main_classes/processors.html#squad">SQuAD processors</a>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers.data.processors.squad</span> <span class="kn">import</span> <span class="n">SquadV2Processor</span>

<span class="c1"># This processor loads the SQuAD2.0 dev set examples</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">SquadV2Processor</span><span class="p">()</span>
<span class="n">examples</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">get_dev_examples</span><span class="p">(</span><span class="s2">"data/squad/"</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">"dev-v2.0.json"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 35/35 [00:04&lt;00:00,  7.31it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>11873
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While <code>examples</code> is a list, most other tasks we'll work with use a unique identifier - one for each question in the dev set.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># generate some maps to help us identify examples of interest</span>
<span class="n">qid_to_example_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">example</span><span class="o">.</span><span class="n">qas_id</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">examples</span><span class="p">)}</span>
<span class="n">qid_to_has_answer</span> <span class="o">=</span> <span class="p">{</span><span class="n">example</span><span class="o">.</span><span class="n">qas_id</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">answers</span><span class="p">)</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">}</span>
<span class="n">answer_qids</span> <span class="o">=</span> <span class="p">[</span><span class="n">qas_id</span> <span class="k">for</span> <span class="n">qas_id</span><span class="p">,</span> <span class="n">has_answer</span> <span class="ow">in</span> <span class="n">qid_to_has_answer</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">has_answer</span><span class="p">]</span>
<span class="n">no_answer_qids</span> <span class="o">=</span> <span class="p">[</span><span class="n">qas_id</span> <span class="k">for</span> <span class="n">qas_id</span><span class="p">,</span> <span class="n">has_answer</span> <span class="ow">in</span> <span class="n">qid_to_has_answer</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">has_answer</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">display_example</span><span class="p">(</span><span class="n">qid</span><span class="p">):</span>    
    <span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

    <span class="n">idx</span> <span class="o">=</span> <span class="n">qid_to_example_index</span><span class="p">[</span><span class="n">qid</span><span class="p">]</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">question_text</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">context_text</span>
    <span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="n">answer</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">answers</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Example </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">---------------------'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q: </span><span class="si">{</span><span class="n">q</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Context:"</span><span class="p">)</span>
    <span class="n">pprint</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">True Answers:</span><span class="se">\n</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="A-positive-example">
<a class="anchor" href="#A-positive-example" aria-hidden="true"><span class="octicon octicon-link"></span></a>A positive example<a class="anchor-link" href="#A-positive-example"> </a>
</h4>
<p>Approximately 50% of the examples in the dev set are questions that have answers contained within their corresponding passage. In these cases, up to five possible correct answers are provided (questions and answers were generated and identified by crowd-sourced workers). Answers must be direct excerpts from the passage but we can see there are several ways to have a "correct" answer.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">display_example</span><span class="p">(</span><span class="n">answer_qids</span><span class="p">[</span><span class="mi">1300</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Example 2548 of 11873
---------------------
Q: Where on Earth is free oxygen found?

Context:
("Free oxygen also occurs in solution in the world's water bodies. The "
 'increased solubility of O\n'
 '2 at lower temperatures (see Physical properties) has important implications '
 'for ocean life, as polar oceans support a much higher density of life due to '
 'their higher oxygen content. Water polluted with plant nutrients such as '
 'nitrates or phosphates may stimulate growth of algae by a process called '
 'eutrophication and the decay of these organisms and other biomaterials may '
 'reduce amounts of O\n'
 '2 in eutrophic water bodies. Scientists assess this aspect of water quality '
 "by measuring the water's biochemical oxygen demand, or the amount of O\n"
 '2 needed to restore it to a normal concentration.')

True Answers:
['water', "in solution in the world's water bodies", "the world's water bodies"]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="A-negative-example">
<a class="anchor" href="#A-negative-example" aria-hidden="true"><span class="octicon octicon-link"></span></a>A negative example<a class="anchor-link" href="#A-negative-example"> </a>
</h4>
<p>The other half of the questions in dev set do not have an answer in the corresponding passage. These questions were generated by crowd-sourced workers to be related and relevant to the passage but unanswerable by that passage. There are thus no True Answers associated with these questions as we see in the example below.</p>
<p>Note: In this case, the question is a trick -- the numbers are reoriented in a way that no longer holds true. Will the model pick up on that?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">display_example</span><span class="p">(</span><span class="n">no_answer_qids</span><span class="p">[</span><span class="mi">1254</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Example 2564 of 11873
---------------------
Q: What happened 3.7-2 billion years ago?

Context:
("Free oxygen gas was almost nonexistent in Earth's atmosphere before "
 'photosynthetic archaea and bacteria evolved, probably about 3.5 billion '
 'years ago. Free oxygen first appeared in significant quantities during the '
 'Paleoproterozoic eon (between 3.0 and 2.3 billion years ago). For the first '
 'billion years, any free oxygen produced by these organisms combined with '
 'dissolved iron in the oceans to form banded iron formations. When such '
 'oxygen sinks became saturated, free oxygen began to outgas from the oceans '
 '3–2.7 billion years ago, reaching 10% of its present level around 1.7 '
 'billion years ago.')

True Answers:
[]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Metrics-for-QA">
<a class="anchor" href="#Metrics-for-QA" aria-hidden="true"><span class="octicon octicon-link"></span></a>Metrics for QA<a class="anchor-link" href="#Metrics-for-QA"> </a>
</h1>
<p>There are two dominant metrics used by many question answering datasets, including SQuAD: exact match (EM) and F1 score. These scores are computed on individual question+answer pairs. When multiple correct answers are possible for a given question, the maximum score over all possible correct answers is computed. Overall EM and F1 scores are computed for a model by averaging over the individual example scores.</p>
<h3 id="Exact-Match">
<a class="anchor" href="#Exact-Match" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exact Match<a class="anchor-link" href="#Exact-Match"> </a>
</h3>
<p>This metric is as simple as it sounds. For each question+answer pair, if the <em>characters</em> of the model's prediction exactly match the characters of (one of) the true answer(s), EM = 1, otherwise EM = 0. This is a strict all-or-nothing metric; being off by a single character results in a score of 0. When assessing against a negative example, if the model predicts any text at all it automatically receives a 0 for that example.</p>
<h3 id="F1">
<a class="anchor" href="#F1" aria-hidden="true"><span class="octicon octicon-link"></span></a>F1<a class="anchor-link" href="#F1"> </a>
</h3>
<p>F1 score is a common metric for classification problems, and widely used in QA. It is appropriate when we care equally about precision and recall. In this case, it's computed over the individual <em>words</em> in the prediction against those in the true answer.  The number of shared words between the prediction and the truth is the basis of the F1 score: precision is the ratio of the number of shared words to the total number of words in the <em>prediction</em>, and recall is the ratio of the number of shared words to the total number of words in the <em>ground truth</em>.</p>
<p><img src="/images/copied_from_nb/my_icons/f1score.png" alt="" title="F1 score"></p>
<p>Let's see how these metrics work in practice. We'll load up a fine-tuned model (<a href="https://huggingface.co/twmkn9/distilbert-base-uncased-squad2">this one</a>, to be precise) and its tokenizer and compare our predictions against the True Answers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-a-Transformer-model-fine-tuned-on-SQuAD-2.0">
<a class="anchor" href="#Load-a-Transformer-model-fine-tuned-on-SQuAD-2.0" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load a Transformer model fine-tuned on SQuAD 2.0<a class="anchor-link" href="#Load-a-Transformer-model-fine-tuned-on-SQuAD-2.0"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"twmkn9/distilbert-base-uncased-squad2"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"twmkn9/distilbert-base-uncased-squad2"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.
  category=FutureWarning,
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following <code>get_prediction</code> method is essentially identical to what we used last time in our simple QA system.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_prediction</span><span class="p">(</span><span class="n">qid</span><span class="p">):</span>
    <span class="c1"># given a question id (qas_id or qid), load the example, get the model outputs and generate an answer</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">qid_to_example_index</span><span class="p">[</span><span class="n">qid</span><span class="p">]]</span><span class="o">.</span><span class="n">question_text</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">qid_to_example_index</span><span class="p">[</span><span class="n">qid</span><span class="p">]]</span><span class="o">.</span><span class="n">context_text</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">answer_start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Get the most likely beginning of answer with the argmax of the score</span>
    <span class="n">answer_end</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span> 

    <span class="n">answer</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_string</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">answer_start</span><span class="p">:</span><span class="n">answer_end</span><span class="p">]))</span>

    <span class="k">return</span> <span class="n">answer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below are some functions we'll need to compute our quality metrics.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># These functions are heavily influenced by the HF squad_metrics.py script</span>
<span class="k">def</span> <span class="nf">normalize_text</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="sd">"""Removing articles and punctuation, and standardizing whitespace are all typical text processing steps."""</span>
    <span class="kn">import</span> <span class="nn">string</span><span class="o">,</span> <span class="nn">re</span>

    <span class="k">def</span> <span class="nf">remove_articles</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\b(a|an|the)\b"</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">UNICODE</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">regex</span><span class="p">,</span> <span class="s2">" "</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">white_space_fix</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">remove_punc</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="n">exclude</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ch</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="n">ch</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">exclude</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">lower</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">white_space_fix</span><span class="p">(</span><span class="n">remove_articles</span><span class="p">(</span><span class="n">remove_punc</span><span class="p">(</span><span class="n">lower</span><span class="p">(</span><span class="n">s</span><span class="p">))))</span>

<span class="k">def</span> <span class="nf">compute_exact_match</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">truth</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">normalize_text</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">==</span> <span class="n">normalize_text</span><span class="p">(</span><span class="n">truth</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">compute_f1</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">truth</span><span class="p">):</span>
    <span class="n">pred_tokens</span> <span class="o">=</span> <span class="n">normalize_text</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">truth_tokens</span> <span class="o">=</span> <span class="n">normalize_text</span><span class="p">(</span><span class="n">truth</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    
    <span class="c1"># if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">truth_tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">pred_tokens</span> <span class="o">==</span> <span class="n">truth_tokens</span><span class="p">)</span>
    
    <span class="n">common_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">)</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">truth_tokens</span><span class="p">)</span>
    
    <span class="c1"># if there are no common tokens then f1 = 0</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    
    <span class="n">prec</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_tokens</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">)</span>
    <span class="n">rec</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_tokens</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">truth_tokens</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">prec</span> <span class="o">*</span> <span class="n">rec</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span> <span class="o">+</span> <span class="n">rec</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_gold_answers</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
    <span class="sd">"""helper function that retrieves all possible true answers from a squad2.0 example"""</span>
    
    <span class="n">gold_answers</span> <span class="o">=</span> <span class="p">[</span><span class="n">answer</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">example</span><span class="o">.</span><span class="n">answers</span> <span class="k">if</span> <span class="n">answer</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]]</span>

    <span class="c1"># if gold_answers doesn't exist it's because this is a negative example - </span>
    <span class="c1"># the only correct answer is an empty string</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">gold_answers</span><span class="p">:</span>
        <span class="n">gold_answers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">""</span><span class="p">]</span>
        
    <span class="k">return</span> <span class="n">gold_answers</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the following cell, we start by computing EM and F1 for our first example - the one that has several True Answers associated with it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">get_prediction</span><span class="p">(</span><span class="n">answer_qids</span><span class="p">[</span><span class="mi">1300</span><span class="p">])</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">qid_to_example_index</span><span class="p">[</span><span class="n">answer_qids</span><span class="p">[</span><span class="mi">1300</span><span class="p">]]]</span>

<span class="n">gold_answers</span> <span class="o">=</span> <span class="n">get_gold_answers</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

<span class="n">em_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">((</span><span class="n">compute_exact_match</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">answer</span><span class="p">))</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">gold_answers</span><span class="p">)</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">((</span><span class="n">compute_f1</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">answer</span><span class="p">))</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">gold_answers</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Question: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">question_text</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prediction: </span><span class="si">{</span><span class="n">prediction</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"True Answers: </span><span class="si">{</span><span class="n">gold_answers</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"EM: </span><span class="si">{</span><span class="n">em_score</span><span class="si">}</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> F1: </span><span class="si">{</span><span class="n">f1_score</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Question: Where on Earth is free oxygen found?
Prediction: water bodies
True Answers: ['water', "in solution in the world's water bodies", "the world's water bodies"]
EM: 0 	 F1: 0.8
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We see that our prediction is actually quite close to some of the True Answers resulting in a respectable F1 score. However, it does not exactly match any of them so our EM score is 0.</p>
<p>Let's try with our negative example now.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">get_prediction</span><span class="p">(</span><span class="n">no_answer_qids</span><span class="p">[</span><span class="mi">1254</span><span class="p">])</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">qid_to_example_index</span><span class="p">[</span><span class="n">no_answer_qids</span><span class="p">[</span><span class="mi">1254</span><span class="p">]]]</span>

<span class="n">gold_answers</span> <span class="o">=</span> <span class="n">get_gold_answers</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

<span class="n">em_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">((</span><span class="n">compute_exact_match</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">answer</span><span class="p">))</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">gold_answers</span><span class="p">)</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">((</span><span class="n">compute_f1</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">answer</span><span class="p">))</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">gold_answers</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Question: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">question_text</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prediction: </span><span class="si">{</span><span class="n">prediction</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"True Answers: </span><span class="si">{</span><span class="n">gold_answers</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"EM: </span><span class="si">{</span><span class="n">em_score</span><span class="si">}</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> F1: </span><span class="si">{</span><span class="n">f1_score</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Question: What happened 3.7-2 billion years ago?
Prediction: [CLS] what happened 3 . 7 - 2 billion years ago ? [SEP] free oxygen gas was almost nonexistent in earth ' s atmosphere before photosynthetic archaea and bacteria evolved , probably about 3 . 5 billion years ago . free oxygen first appeared in significant quantities during the paleoproterozoic eon ( between 3 . 0 and 2 . 3 billion years ago ) . for the first billion years , any free oxygen produced by these organisms combined with dissolved iron in the oceans to form banded iron formations . when such oxygen sinks became saturated , free oxygen began to outgas from the oceans
True Answers: ['']
EM: 0 	 F1: 0
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Wow. Both our metrics are zero because this model does not correctly asses that this question is unanswerable! Even worse, it seems to have catastrophically failed, including the entire question as part of the answer. In a later section we'll explicitly dig into why this happens but for now it's important to note that we got this answer because we simply extracted start and end tokens associated with the maximum score (we took an <code>argmax</code> of the model output in <code>get_prediction</code>) and this leads to some unintended consequences.</p>
<p>Now that we have the basics of computing QA metrics on a couple of examples, we need to assess the model on the entire dev set. Luckily, there's a script for that.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Evaluating-a-model-on-the-SQuAD2.0-dev-set-with-HF">
<a class="anchor" href="#Evaluating-a-model-on-the-SQuAD2.0-dev-set-with-HF" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evaluating a model on the SQuAD2.0 dev set with HF<a class="anchor-link" href="#Evaluating-a-model-on-the-SQuAD2.0-dev-set-with-HF"> </a>
</h1>
<p>The same <code>run_squad.py</code> script we used to fine-tune a Transformer for question answering can also be used to evaluate the model. You can grab the script <a href="https://github.com/huggingface/transformers/blob/master/examples/question-answering/run_squad.py">here</a> or run the hidden cell below.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># collapse-hide</span>

<span class="c1"># Grab the run_squad.py script</span>
<span class="o">!</span>curl -L -O https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 34442  100 34442    0     0   148k      0 --:--:-- --:--:-- --:--:--  148k
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below are the arguments you'll need to properly evaluate a fine-tuned model for question answering on the SQuAD dev set. Because we're using SQuAD2.0 it is <strong>crucial</strong> that you include the <code>--version_2_with_negative</code> flag!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python run_squad.py  <span class="err">\</span>
    <span class="o">--</span><span class="n">model_type</span> <span class="n">distilbert</span>   \
    <span class="o">--</span><span class="n">model_name_or_path</span> <span class="n">twmkn9</span><span class="o">/</span><span class="n">distilbert</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">uncased</span><span class="o">-</span><span class="n">squad2</span>  \
    <span class="o">--</span><span class="n">output_dir</span> <span class="n">models</span><span class="o">/</span><span class="n">distilbert</span><span class="o">/</span><span class="n">twmkn9_distilbert</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">uncased</span><span class="o">-</span><span class="n">squad2</span> \
    <span class="o">--</span><span class="n">data_dir</span> <span class="n">data</span><span class="o">/</span><span class="n">squad</span>   \
    <span class="o">--</span><span class="n">predict_file</span> <span class="n">dev</span><span class="o">-</span><span class="n">v2</span><span class="o">.</span><span class="mf">0.</span><span class="n">json</span>   \
    <span class="o">--</span><span class="n">do_eval</span>   \
    <span class="o">--</span><span class="n">version_2_with_negative</span> \
    <span class="o">--</span><span class="n">do_lower_case</span>  \
    <span class="o">--</span><span class="n">per_gpu_eval_batch_size</span> <span class="mi">12</span>   \
    <span class="o">--</span><span class="n">max_seq_length</span> <span class="mi">384</span>   \
    <span class="o">--</span><span class="n">doc_stride</span> <span class="mi">128</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Refer to our last post for more details on what these arguments mean and what this script does. For our immediate purposes, running the cell above will produce the following output in the <code>--output_dir</code> directory:</p>
<ul>
<li><code>predictions_.json</code></li>
<li><code>nbest_predictions_.json</code></li>
<li><code>null_odds_.json</code></li>
</ul>
<p>We'll go over what these are later on. Additionally, an overall <code>Results</code> dict will be displayed to the screen. If you run the above cell, the last line of output should display something like the following:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Results</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># a) Scores averaged over all examples in the dev set</span>
    <span class="s1">'exact'</span><span class="p">:</span> <span class="mf">66.25958056093658</span><span class="p">,</span>         
    <span class="s1">'f1'</span><span class="p">:</span> <span class="mf">69.66994428499025</span><span class="p">,</span>            
    <span class="s1">'total'</span><span class="p">:</span> <span class="mi">11873</span><span class="p">,</span>  <span class="c1"># number of examples in the dev set</span>
    
    <span class="c1"># b) Scores averaged over only positive examples (have answers)</span>
    <span class="s1">'HasAns_exact'</span><span class="p">:</span> <span class="mf">68.91025641025641</span><span class="p">,</span>  
    <span class="s1">'HasAns_f1'</span><span class="p">:</span> <span class="mf">75.74076391627662</span><span class="p">,</span>     
    <span class="s1">'HasAns_total'</span><span class="p">:</span> <span class="mi">5928</span><span class="p">,</span> <span class="c1"># number of positive examples</span>
    
    <span class="c1"># c) Scores averaged over only negative examples (no answers)</span>
    <span class="s1">'NoAns_exact'</span><span class="p">:</span> <span class="mf">63.61648444070648</span><span class="p">,</span> 
    <span class="s1">'NoAns_f1'</span><span class="p">:</span> <span class="mf">63.61648444070648</span><span class="p">,</span> 
    <span class="s1">'NoAns_total'</span><span class="p">:</span> <span class="mi">5945</span><span class="p">,</span> <span class="c1"># number of negative examples</span>
    
    <span class="c1"># d) Given probabilities of no-answer for each example, what would the best scores and thresholds be?</span>
    <span class="s1">'best_exact'</span><span class="p">:</span> <span class="mf">66.25958056093658</span><span class="p">,</span> 
    <span class="s1">'best_exact_thresh'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> 
    <span class="s1">'best_f1'</span><span class="p">:</span> <span class="mf">69.66994428499046</span><span class="p">,</span> 
    <span class="s1">'best_f1_thresh'</span><span class="p">:</span> <span class="mf">0.0</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first three blocks of the <code>Results</code> output are pretty straightforward. EM and F1 scores are reported over a) the full dev set, b) the set of positive examples, and c) the set of negative examples. This can give you some insight into whether your model is performing adequately on both answer and no-answer questions (this particular model is pretty bad at no-answer questions).</p>
<p>However, what's going on with the last block? This portion of the output is not useful unless you supply the evaluation method with additional information. For that we'll need to dig deeper into the evaluation process because it turns out that we need to compute more than just a prediction for an answer - we must also compute a prediction for NO answer and we must score both predictions!</p>
<p>The following section will walk through the technical details of computing robust predictions on SQuAD2.0 examples, including how to score an answer and the null answer, as well as how to determine which one should be the "correct" prediction for a given example. Feel free to jump ahead to the next section if you want to get to the punchline, however, for those of you considering building your own QA system, I found this information to be invaluable for understanding the inner workings of prediction and assessment.</p>
<h3 id="[Optional/highly-technical]-Computing-predictions">
<a class="anchor" href="#%5BOptional/highly-technical%5D-Computing-predictions" aria-hidden="true"><span class="octicon octicon-link"></span></a>[Optional/highly technical] Computing predictions<a class="anchor-link" href="#%5BOptional/highly-technical%5D-Computing-predictions"> </a>
</h3>
<p>Note: The code in the following section is an under-the-hood dive into the HF <code>compute_predictions_logits</code> method in their <code>squad_metrics.py</code> script.</p>
<p>When the tokenized question+context is passed to the model, the output consists of two sets of logits: one for the start of the answer span, the other for the end of the answer span. These logits represent the likelihood of any given token being the start or end of the answer. Every token passed to the model is assigned a logit, including special tokens (e.g, [CLS], [SEP]), and tokens corresponding to the question itself.</p>
<p>Let's walk through the process using our last example (Q: What happened 3.7-2 billion years ago?).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">question_text</span><span class="p">,</span> <span class="n">example</span><span class="o">.</span><span class="n">context_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>
<span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Look at how large the logit is in the [CLS] position (index 0)!  </span>
<span class="c1"># Strong possibility that this question has no answer... but our prediction returned an answer anyway!</span>
<span class="n">start_logits</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[  6.4914,  -9.1416,  -8.4068,  -7.5684,  -9.9081,  -9.4256, -10.1625,
          -9.2579, -10.0554,  -9.9653,  -9.2002,  -8.8657,  -9.1162,   0.6481,
          -2.5947,  -4.5072,  -8.1189,  -6.5871,  -5.8973, -10.8619, -11.0953,
         -10.2294,  -9.3660,  -7.6017, -10.8009, -10.8197,  -6.1258,  -8.3507,
          -4.2463, -10.0987, -10.2659,  -8.8490,  -6.7346,  -8.6513,  -9.7573,
          -5.7496,  -5.5851,  -8.9483,  -7.0652,  -6.1369,  -5.7810,  -9.4366,
          -8.7670,  -9.6743,  -9.7446,  -7.7905,  -7.4541,  -1.5963,  -3.8540,
          -7.3450,  -8.1854,  -9.5566,  -8.3416,  -8.9553,  -8.3144,  -6.4132,
          -4.2285,  -9.4427,  -9.5111,  -9.2931,  -8.9154,  -9.3930,  -8.2111,
          -8.9774,  -9.0274,  -7.2652,  -7.4511,  -9.8597,  -9.5869,  -9.9735,
          -7.0526,  -9.7560,  -8.7788,  -9.5117,  -9.6391,  -8.6487,  -9.5994,
          -7.8213,  -5.1754,  -4.3561,  -4.3913,  -7.8499,  -7.7522,  -8.9651,
          -3.5229,  -0.8312,  -2.7668,  -7.9180, -10.0320,  -8.7797,  -4.5965,
          -5.9465,  -9.9442,  -3.2135,  -5.0734,  -8.3462,  -7.5366,  -3.7073,
          -7.0968,  -4.3325,  -1.3691,  -4.1477,  -5.3794,  -7.6138,   1.3183,
          -3.4190,   3.1457,  -3.0152,  -0.4102,  -2.4606,  -3.5971,   6.4519,
          -0.5654,   0.9829,  -1.6682,   3.3549,  -4.7847,  -2.8024,  -3.3160,
          -0.5868,  -0.9617,  -8.1925,  -4.3299,  -7.3923,  -5.0875,  -5.3880,
          -5.3676,  -3.0878,  -4.3427,   4.3975,   1.8860,  -5.4661,  -9.1565,
          -3.6369,  -3.5462,  -4.1448,  -2.0250,  -2.4492,  -8.7015,  -7.3292,
          -7.7616,  -7.0786,  -4.6668,  -4.4088,  -9.1182]],
       grad_fn=&lt;SqueezeBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In our simple QA system, we predicted the best answer by selecting the start and end tokens with the largest logits, but that's not very robust. In fact, the original BERT paper suggested considering any sensible start+end combination as a possible answer to the question. These combinations would then be scored, and the one with the highest score would be considered the best answer. A possible (candidate) answer is scored as the sum of its start and end logits. 
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>This reflects how a basic span extraction classifier works. The raw hidden layer from the model is passed through a <code>Linear</code> layer and then fed to a <code>CrossEntropyLoss</code> for each class. In span extraction, there are two classes: the beginning of the span and the end of the span. The span loss is computed as the sum of the <code>CrossEntropyLoss</code> for the start and end positions. The probability of an answer span is the interesection of the probabilities of the start and end tokens: P(S n E) = P(S)P(E) because the start and end tokens are treated as being independent. Thus summing the start and end logits is equivalent to a product of their softmax probabilities. 
</div>
<p>Let's see it in practice.</p>
<p>To mimic this behavior we'll start by taking the <em>n</em> largest <code>start_logits</code> and the <em>n</em> largest <code>end_logits</code> as candidates. Any sensible combination of these start + end tokens is considered a candidate answer, however, several consistency checks must first be performed. For example, an answer wherein the end token falls <em>before</em> the start token should be excluded because that just doesn't make sense. Candidate answers wherein the start or end tokens are associated with question tokens are also excluded because the answer to the question should obviously not be in the question itself! It is important to note that the [CLS] token and its corresonding logits are <strong>not</strong> removed because this token indicates the null answer.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">to_list</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1"># convert our start and end logit tensors to lists</span>
<span class="n">start_logits</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">start_logits</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">end_logits</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">end_logits</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># sort our start and end logits from largest to smallest, keeping track of the index</span>
<span class="n">start_idx_and_logit</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">start_logits</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">end_idx_and_logit</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">end_logits</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># select the top n (in this case, 5)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">start_idx_and_logit</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">end_idx_and_logit</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(0, 6.491392135620117), (111, 6.451900005340576), (129, 4.39750862121582), (115, 3.354912042617798), (106, 3.1457433700561523)]
[(119, 6.332924842834473), (0, 6.084453105926514), (135, 4.417283058166504), (116, 4.3764238357543945), (112, 4.125302314758301)]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The null answer token (index 0) is in the top five of both the start and end logit lists.</p>
<p>In order to eventually predict a text answer (or empty string), we need to keep track of the indexes which will be used to pull the corresponding token ids later on. We'll also need to identify which indexes correspond to the question tokens so that we can ensure we don't allow a nonsensical prediction.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">start_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">logit</span> <span class="ow">in</span> <span class="n">start_idx_and_logit</span><span class="p">[:</span><span class="mi">5</span><span class="p">]]</span>
<span class="n">end_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">logit</span> <span class="ow">in</span> <span class="n">end_idx_and_logit</span><span class="p">[:</span><span class="mi">5</span><span class="p">]]</span>

<span class="c1"># convert the token ids from a tensor to a list</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># question tokens are defined as those between the CLS token (101, at position 0) and first SEP (102) token </span>
<span class="n">question_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">tokens</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="mi">102</span><span class="p">)])]</span>
<span class="n">question_indexes</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we'll generate a list of candidate predictions by looping through all combinations of the start and end token indexes, excluding nonsensical combinations. We'll save these to a list for the next step.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">collections</span>

<span class="c1"># keep track of all preliminary predictions</span>
<span class="n">PrelimPrediction</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span> 
    <span class="s2">"PrelimPrediction"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"start_index"</span><span class="p">,</span> <span class="s2">"end_index"</span><span class="p">,</span> <span class="s2">"start_logit"</span><span class="p">,</span> <span class="s2">"end_logit"</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">prelim_preds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">start_indexes</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">end_indexes</span><span class="p">:</span>
        <span class="c1"># throw out invalid predictions</span>
        <span class="k">if</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">question_indexes</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">question_indexes</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">end_index</span> <span class="o">&lt;</span> <span class="n">start_index</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">prelim_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">PrelimPrediction</span><span class="p">(</span>
                <span class="n">start_index</span> <span class="o">=</span> <span class="n">start_index</span><span class="p">,</span>
                <span class="n">end_index</span> <span class="o">=</span> <span class="n">end_index</span><span class="p">,</span>
                <span class="n">start_logit</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">[</span><span class="n">start_index</span><span class="p">],</span>
                <span class="n">end_logit</span> <span class="o">=</span> <span class="n">end_logits</span><span class="p">[</span><span class="n">end_index</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With a list of sensible candidate predictions, it's time to score them.</p>
<p>For a candidate answer, score = <code>start_logit</code> + <code>end_logit</code>. Below we sort our candidate predictions by their score.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># sort preliminary predictions by their score</span>
<span class="n">prelim_preds</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">prelim_preds</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">start_logit</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">end_logit</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">prelim_preds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[PrelimPrediction(start_index=0, end_index=119, start_logit=6.491392135620117, end_logit=6.332924842834473),
 PrelimPrediction(start_index=111, end_index=119, start_logit=6.451900005340576, end_logit=6.332924842834473),
 PrelimPrediction(start_index=0, end_index=0, start_logit=6.491392135620117, end_logit=6.084453105926514),
 PrelimPrediction(start_index=0, end_index=135, start_logit=6.491392135620117, end_logit=4.417283058166504),
 PrelimPrediction(start_index=111, end_index=135, start_logit=6.451900005340576, end_logit=4.417283058166504),
 PrelimPrediction(start_index=0, end_index=116, start_logit=6.491392135620117, end_logit=4.3764238357543945),
 PrelimPrediction(start_index=111, end_index=116, start_logit=6.451900005340576, end_logit=4.3764238357543945),
 PrelimPrediction(start_index=0, end_index=112, start_logit=6.491392135620117, end_logit=4.125302314758301),
 PrelimPrediction(start_index=111, end_index=112, start_logit=6.451900005340576, end_logit=4.125302314758301),
 PrelimPrediction(start_index=115, end_index=119, start_logit=3.354912042617798, end_logit=6.332924842834473),
 PrelimPrediction(start_index=106, end_index=119, start_logit=3.1457433700561523, end_logit=6.332924842834473),
 PrelimPrediction(start_index=129, end_index=135, start_logit=4.39750862121582, end_logit=4.417283058166504),
 PrelimPrediction(start_index=115, end_index=135, start_logit=3.354912042617798, end_logit=4.417283058166504),
 PrelimPrediction(start_index=115, end_index=116, start_logit=3.354912042617798, end_logit=4.3764238357543945),
 PrelimPrediction(start_index=106, end_index=135, start_logit=3.1457433700561523, end_logit=4.417283058166504),
 PrelimPrediction(start_index=106, end_index=116, start_logit=3.1457433700561523, end_logit=4.3764238357543945),
 PrelimPrediction(start_index=106, end_index=112, start_logit=3.1457433700561523, end_logit=4.125302314758301)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need to convert our preliminary predictions into actual text (or the empty string if null). We'll keep track of text predictions we've seen because different token combinations can result in the same text prediction and we only want to keep the one with the highest score (we're looping in descending score order). Finally, we'll trim this list down to the best 5 predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># keep track of all best predictions</span>
<span class="n">BestPrediction</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>  <span class="c1"># pylint: disable=invalid-name</span>
    <span class="s2">"BestPrediction"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"text"</span><span class="p">,</span> <span class="s2">"start_logit"</span><span class="p">,</span> <span class="s2">"end_logit"</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">nbest</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">seen_predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">prelim_preds</span><span class="p">:</span>
    
    <span class="c1"># For now we only care about the top 5 best predictions</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nbest</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span> 
        <span class="k">break</span>
        
    <span class="c1"># loop through predictions according to their start index</span>
    <span class="k">if</span> <span class="n">pred</span><span class="o">.</span><span class="n">start_index</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># non-null answers have start_index &gt; 0</span>

        <span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_string</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span>
                <span class="n">tokens</span><span class="p">[</span><span class="n">pred</span><span class="o">.</span><span class="n">start_index</span><span class="p">:</span><span class="n">pred</span><span class="o">.</span><span class="n">end_index</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># Clean whitespace</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">seen_predictions</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="c1"># flag this text as being seen -- if we see it again, don't add to nbest list</span>
        <span class="n">seen_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> 

        <span class="c1"># add this text prediction to a pruned list of the top 5 best predictions</span>
        <span class="n">nbest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BestPrediction</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">start_logit</span><span class="o">=</span><span class="n">pred</span><span class="o">.</span><span class="n">start_logit</span><span class="p">,</span> <span class="n">end_logit</span><span class="o">=</span><span class="n">pred</span><span class="o">.</span><span class="n">end_logit</span><span class="p">))</span>

<span class="c1"># And don't forget -- include the null answer!</span>
<span class="n">nbest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BestPrediction</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span> <span class="n">start_logit</span><span class="o">=</span><span class="n">start_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">end_logit</span><span class="o">=</span><span class="n">end_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The null answer is scored as the sum of the  start_logit and end_logit associated with the [CLS] token.</p>
<p>At this point, we have a neat list of the top 5 best predictions for this question. The number of best predictions for each example is adjustable with the <code>--n_best_size</code> argument of the <code>run_squad.py</code> script.  The <code>nbest</code> predictions for <em>every question</em> in the dev set are saved to disk under <code>nbest_predictions_.json</code> in <code>--output_dir</code>. This is a great resource if you need to dig into how your model is behaving. Let's take a look at our <code>nbest</code> predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nbest</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[BestPrediction(text='free oxygen began to outgas from the oceans', start_logit=6.451900005340576, end_logit=6.332924842834473),
 BestPrediction(text='free oxygen began to outgas from the oceans 3 – 2 . 7 billion years ago , reaching 10 % of its present level', start_logit=6.451900005340576, end_logit=4.417283058166504),
 BestPrediction(text='free oxygen began to outgas', start_logit=6.451900005340576, end_logit=4.3764238357543945),
 BestPrediction(text='free oxygen', start_logit=6.451900005340576, end_logit=4.125302314758301),
 BestPrediction(text='outgas from the oceans', start_logit=3.354912042617798, end_logit=6.332924842834473),
 BestPrediction(text='', start_logit=6.491392135620117, end_logit=6.084453105926514)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our top prediction so far is "free oxygen began to outgas from the oceans" which is already a far cry better than what we originally predicted. This is because we have successfully excluded nonsensical predictions that would incorporate question tokens as part of the answer. However, we know it's still incorrect. Let's keep going.</p>
<p>The last step is to compute the the null score -- more specifically, the difference between the null score and the best non-null score as shown below.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compute the null score as the sum of the [CLS] token logits</span>
<span class="n">score_null</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">end_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># compute the difference between the null score and the best non-null score</span>
<span class="n">score_diff</span> <span class="o">=</span> <span class="n">score_null</span> <span class="o">-</span> <span class="n">nbest</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">start_logit</span> <span class="o">-</span> <span class="n">nbest</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">end_logit</span>

<span class="n">score_diff</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>-0.20897960662841797</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This <code>score_diff</code> is computed for every example in the dev set and these scores are saved to disk in the <code>null_odds_.json</code>. Let's pull up the score stored for the example we're using and see how we did!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">filename</span> <span class="o">=</span> <span class="n">model_dir</span> <span class="o">+</span> <span class="s1">'null_odds_.json'</span>
<span class="n">null_odds</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">))</span>

<span class="n">null_odds</span><span class="p">[</span><span class="n">example</span><span class="o">.</span><span class="n">qas_id</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>-0.20899391174316406</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We basically nailed it! The full HF version contains a few more checks and some additional subtleties that could account for the slight differences in our <code>score_diff</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-the-null-threshold">
<a class="anchor" href="#Using-the-null-threshold" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using the null threshold<a class="anchor-link" href="#Using-the-null-threshold"> </a>
</h3>
<p>In the previous section we covered</p>
<ul>
<li>how to generate more robust predictions (e.g. by excluding predictions that include question tokens in the answer),</li>
<li>how to score a prediction as the sum of its start and end logits</li>
<li>how to compute the score difference between the null prediction and the best text prediction</li>
</ul>
<p>The <code>run_squad.py</code> script performs all of these tasks for us and saves the score differences for every example in the <code>null_odds_.json</code>. With that, we can now start to make sense of the fourth block of the results output!</p>
<p>According to the original <a href="https://arxiv.org/abs/1810.04805">BERT paper</a>,</p>
<blockquote>
<p>We predict a non-null answer when sˆi,j &gt; s_null + τ , where the threshold τ is selected on the dev set to maximize F1.</p>
</blockquote>
<p>In other words, the authors are saying that one should predict a null answer for a given example if that example's score difference is above a certain threshold. What should that threshold be? How should we compute it? They give us a recipe:select the threshold that maximizes F1. 
Rather then rerunning <code>run_squad.py</code>, we can import the aptly-named method that computes SQuAD evaluation: <code>squad_evaluate</code>. You can take a look at the code for yourself <a href="https://github.com/huggingface/transformers/blob/5856999a9f2926923f037ecd8d27b8058bcf9dae/src/transformers/data/metrics/squad_metrics.py#L211-L239">here</a>. To use it we'll need</p>
<ul>
<li>the original examples (because that's where the True Answers are stored),</li>
<li><code>predictions_.json</code></li>
<li><code>null_odds_.json</code></li>
<li>and a null threshold</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers.data.metrics.squad_metrics</span> <span class="kn">import</span> <span class="n">squad_evaluate</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load the predictions we generated earlier</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">model_dir</span> <span class="o">+</span> <span class="s1">'predictions_.json'</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">))</span>

<span class="c1"># Load the null score differences we generated earlier</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">model_dir</span> <span class="o">+</span> <span class="s1">'null_odds_.json'</span>
<span class="n">null_odds</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's re-evaluate our model on SQuAD2.0 using the <code>squad_evaluate</code> method. This method uses the score differences for each example in the dev set to determine thresholds that maximize either the EM score or the F1 score. It then recomputes the best possible EM score and F1 score associated with that null threshold.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># The default threshold is set to 1.0 -- we'll leave it there for now</span>
<span class="n">results_default_thresh</span> <span class="o">=</span> <span class="n">squad_evaluate</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> 
                                        <span class="n">preds</span><span class="p">,</span> 
                                        <span class="n">no_answer_probs</span><span class="o">=</span><span class="n">null_odds</span><span class="p">,</span> 
                                        <span class="n">no_answer_probability_threshold</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results_default_thresh</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>OrderedDict([('exact', 66.25958056093658),
             ('f1', 69.66994428499025),
             ('total', 11873),
             ('HasAns_exact', 68.91025641025641),
             ('HasAns_f1', 75.74076391627662),
             ('HasAns_total', 5928),
             ('NoAns_exact', 63.61648444070648),
             ('NoAns_f1', 63.61648444070648),
             ('NoAns_total', 5945),
             ('best_exact', 68.36519834919565),
             ('best_exact_thresh', -4.189249038696289),
             ('best_f1', 71.1144383018176),
             ('best_f1_thresh', -3.7676548957824707)])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first three blocks have identical values as our first evaluation because they are based on the default threshold (which is currently 1.0). However, the values in the fourth block have been updated by taking into account the <code>null_odds</code> information.  When a given example's <code>score_diff</code> is greater than the threshold, the prediction is flipped to a null answer which affects the overall EM and F1 scores.</p>
<p>Let's use the <code>best_f1_thresh</code> and run the evaluation once more to see a breakdown our model's performance on <code>HasAns</code> and <code>NoAns</code> examples:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_f1_thresh</span> <span class="o">=</span> <span class="o">-</span><span class="mf">3.7676548957824707</span>
<span class="n">results_f1_thresh</span> <span class="o">=</span> <span class="n">squad_evaluate</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> 
                                   <span class="n">preds</span><span class="p">,</span> 
                                   <span class="n">no_answer_probs</span><span class="o">=</span><span class="n">null_odds</span><span class="p">,</span> 
                                   <span class="n">no_answer_probability_threshold</span><span class="o">=</span><span class="n">best_f1_thresh</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results_f1_thresh</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>OrderedDict([('exact', 68.31466352227744),
             ('f1', 71.11443830181771),
             ('total', 11873),
             ('HasAns_exact', 61.53846153846154),
             ('HasAns_f1', 67.14604014127524),
             ('HasAns_total', 5928),
             ('NoAns_exact', 75.07148864592094),
             ('NoAns_f1', 75.07148864592094),
             ('NoAns_total', 5945),
             ('best_exact', 68.36519834919565),
             ('best_exact_thresh', -4.189249038696289),
             ('best_f1', 71.1144383018176),
             ('best_f1_thresh', -3.7676548957824707)])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When we used the default threshold of 1.0, we saw that our <code>NoAns_f1</code> score was a mere 63.6 but when we use the <code>best_f1_thresh</code>, we now get a <code>NoAns_f1</code> score of 75! Nearly a 12 point jump! The downside is that we lose some ground in how well our model correctly predicts <code>HasAns</code> examples. Overall, however, we see a net increase of a couple points in both EM and F1 scores. This demonstrates that computing null scores and properly using a null threshold significantly increases QA performance on the SQuAD2.0 dev set with almost no additional work.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Putting-it-all-together">
<a class="anchor" href="#Putting-it-all-together" aria-hidden="true"><span class="octicon octicon-link"></span></a>Putting it all together<a class="anchor-link" href="#Putting-it-all-together"> </a>
</h1>
<p>Below we have a new method that will select more robust predictions, compute scores for the best text predictions as well as for the null prediction, and will use these scores along with a null threshold to determine whether the question should be answered. As a bonus, this method also computes and returns the probability of the answer which is often easier to interpret than a logit score. Prediction probabilities depend on <code>nbest</code> since they are computed with a softmax over the number of most likely predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_robust_prediction</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">nbest</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">null_threshold</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">get_qa_inputs</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
    <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

    <span class="c1"># get sensible preliminary predictions, sorted by score</span>
    <span class="n">prelim_preds</span> <span class="o">=</span> <span class="n">preliminary_predictions</span><span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> 
                                           <span class="n">end_logits</span><span class="p">,</span> 
                                           <span class="n">inputs</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">],</span>
                                           <span class="n">nbest</span><span class="p">)</span>
    
    <span class="c1"># narrow that down to the top nbest predictions</span>
    <span class="n">nbest_preds</span> <span class="o">=</span> <span class="n">best_predictions</span><span class="p">(</span><span class="n">prelim_preds</span><span class="p">,</span> <span class="n">nbest</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>

    <span class="c1"># Compute the probability of each prediction - nice but not necessary</span>
    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">prediction_probabilities</span><span class="p">(</span><span class="n">nbest_preds</span><span class="p">)</span>
        
    <span class="c1"># compute score difference</span>
    <span class="n">score_difference</span> <span class="o">=</span> <span class="n">compute_score_difference</span><span class="p">(</span><span class="n">nbest_preds</span><span class="p">)</span>

    <span class="c1"># If score difference &gt; threshold, return the null answer</span>
    <span class="k">if</span> <span class="n">score_difference</span> <span class="o">&gt;</span> <span class="n">null_threshold</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">""</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nbest_preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># collapse-hide</span>

<span class="c1"># ----------------- Helper functions for get_robust_prediction ----------------- #</span>
<span class="k">def</span> <span class="nf">get_qa_inputs</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="c1"># load the example, convert to inputs, get model outputs</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">example</span><span class="o">.</span><span class="n">question_text</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">example</span><span class="o">.</span><span class="n">context_text</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_clean_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_string</span><span class="p">(</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="c1"># Clean whitespace</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">prediction_probabilities</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="sd">"""Compute softmax values for each sets of scores in x."""</span>
        <span class="n">e_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">e_x</span> <span class="o">/</span> <span class="n">e_x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="n">all_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">pred</span><span class="o">.</span><span class="n">start_logit</span><span class="o">+</span><span class="n">pred</span><span class="o">.</span><span class="n">end_logit</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span> 
    <span class="k">return</span> <span class="n">softmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_scores</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">preliminary_predictions</span><span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">nbest</span><span class="p">):</span>
    <span class="c1"># convert tensors to lists</span>
    <span class="n">start_logits</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">start_logits</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">end_logits</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">end_logits</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># sort our start and end logits from largest to smallest, keeping track of the index</span>
    <span class="n">start_idx_and_logit</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">start_logits</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">end_idx_and_logit</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">end_logits</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">start_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">logit</span> <span class="ow">in</span> <span class="n">start_idx_and_logit</span><span class="p">[:</span><span class="n">nbest</span><span class="p">]]</span>
    <span class="n">end_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">logit</span> <span class="ow">in</span> <span class="n">end_idx_and_logit</span><span class="p">[:</span><span class="n">nbest</span><span class="p">]]</span>

    <span class="c1"># question tokens are between the CLS token (101, at position 0) and first SEP (102) token </span>
    <span class="n">question_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">tokens</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="mi">102</span><span class="p">)])]</span>

    <span class="c1"># keep track of all preliminary predictions</span>
    <span class="n">PrelimPrediction</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>  <span class="c1"># pylint: disable=invalid-name</span>
        <span class="s2">"PrelimPrediction"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"start_index"</span><span class="p">,</span> <span class="s2">"end_index"</span><span class="p">,</span> <span class="s2">"start_logit"</span><span class="p">,</span> <span class="s2">"end_logit"</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">prelim_preds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">start_indexes</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">end_indexes</span><span class="p">:</span>
            <span class="c1"># throw out invalid predictions</span>
            <span class="k">if</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">question_indexes</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">question_indexes</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">end_index</span> <span class="o">&lt;</span> <span class="n">start_index</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">prelim_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">PrelimPrediction</span><span class="p">(</span>
                    <span class="n">start_index</span> <span class="o">=</span> <span class="n">start_index</span><span class="p">,</span>
                    <span class="n">end_index</span> <span class="o">=</span> <span class="n">end_index</span><span class="p">,</span>
                    <span class="n">start_logit</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">[</span><span class="n">start_index</span><span class="p">],</span>
                    <span class="n">end_logit</span> <span class="o">=</span> <span class="n">end_logits</span><span class="p">[</span><span class="n">end_index</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span>
    <span class="c1"># sort prelim_preds in descending score order</span>
    <span class="n">prelim_preds</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">prelim_preds</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">start_logit</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">end_logit</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prelim_preds</span>

<span class="k">def</span> <span class="nf">best_predictions</span><span class="p">(</span><span class="n">prelim_preds</span><span class="p">,</span> <span class="n">nbest</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="c1"># keep track of all best predictions</span>

    <span class="c1"># This will be the pool from which answer probabilities are computed </span>
    <span class="n">BestPrediction</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
        <span class="s2">"BestPrediction"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"text"</span><span class="p">,</span> <span class="s2">"start_logit"</span><span class="p">,</span> <span class="s2">"end_logit"</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">nbest_predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">seen_predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">prelim_preds</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nbest_predictions</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">nbest</span><span class="p">:</span> 
            <span class="k">break</span>
        <span class="k">if</span> <span class="n">pred</span><span class="o">.</span><span class="n">start_index</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># non-null answers have start_index &gt; 0</span>

            <span class="n">toks</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">pred</span><span class="o">.</span><span class="n">start_index</span> <span class="p">:</span> <span class="n">pred</span><span class="o">.</span><span class="n">end_index</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">get_clean_text</span><span class="p">(</span><span class="n">toks</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>

            <span class="c1"># if this text has been seen already - skip it</span>
            <span class="k">if</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">seen_predictions</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># flag text as being seen</span>
            <span class="n">seen_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> 

            <span class="c1"># add this text to a pruned list of the top nbest predictions</span>
            <span class="n">nbest_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">BestPrediction</span><span class="p">(</span>
                    <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> 
                    <span class="n">start_logit</span><span class="o">=</span><span class="n">pred</span><span class="o">.</span><span class="n">start_logit</span><span class="p">,</span>
                    <span class="n">end_logit</span><span class="o">=</span><span class="n">pred</span><span class="o">.</span><span class="n">end_logit</span>
                    <span class="p">)</span>
                <span class="p">)</span>
        
    <span class="c1"># Add the null prediction</span>
    <span class="n">nbest_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">BestPrediction</span><span class="p">(</span>
            <span class="n">text</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span> 
            <span class="n">start_logit</span><span class="o">=</span><span class="n">start_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
            <span class="n">end_logit</span><span class="o">=</span><span class="n">end_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">nbest_predictions</span>

<span class="k">def</span> <span class="nf">compute_score_difference</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
    <span class="sd">""" Assumes that the null answer is always the last prediction """</span>
    <span class="n">score_null</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">start_logit</span> <span class="o">+</span> <span class="n">predictions</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">end_logit</span>
    <span class="n">score_non_null</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">start_logit</span> <span class="o">+</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">end_logit</span>
    <span class="k">return</span> <span class="n">score_null</span> <span class="o">-</span> <span class="n">score_non_null</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Do we now get the right answer (an empty string) for that tricky no-answer example we were working with?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">question_text</span><span class="p">)</span>
<span class="n">get_robust_prediction</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">nbest</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">null_threshold</span><span class="o">=</span><span class="n">best_f1_thresh</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>What happened 3.7-2 billion years ago?
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('', 0.3441245825487927)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Woohoo!! We got the right answer this time!!</p>
<p>Even if we didn't have the best threshold in place, our additional checks still allow us to output more sensible looking answers, rejecting predictions that include the question tokens.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">question_text</span><span class="p">)</span>
<span class="n">get_robust_prediction</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">nbest</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">null_threshold</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>What happened 3.7-2 billion years ago?
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('free oxygen began to outgas from the oceans', 0.42410597159471125)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And if it hadn't been a trick question, this would be the correct answer! Seems like distilBERT could use some improvement in number understanding.</p>
<h1 id="Final-Thoughts">
<a class="anchor" href="#Final-Thoughts" aria-hidden="true"><span class="octicon octicon-link"></span></a>Final Thoughts<a class="anchor-link" href="#Final-Thoughts"> </a>
</h1>
<p>Using a robust prediction method like the above will do more than allow your model to perform better on a curated dev set, though this is an important first step. It will also provide your model with a slightly better ability to refrain from answering questions that simply don't have an answer in the associated passage. This is a crucial feature for QA models because it's not enough to get an answer if that answer doesn't make sense. We want our models to tell us something useful -- and sometimes that means telling us nothing at all.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="fastforwardlabs/ff14_blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/hidden/" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>CFF builds a state-of-the-art QA application with the latest NLP techniques</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastforwardlabs" title="fastforwardlabs"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/FastForwardLabs" title="FastForwardLabs"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
