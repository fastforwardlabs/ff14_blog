{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl0KyQomBQ7l"
   },
   "source": [
    "# Improving the Retriever on a More Natural Dataset\n",
    "> Practical considerations for improving information retrieval in an IR QA system\n",
    "\n",
    "- title: \"Improving the Retriever on a More Natural Dataset\"\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- use_math: true\n",
    "- categories: [elasticsearch, QA system design]\n",
    "- hidden: true\n",
    "- permalink: /hidden-arr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Np3wkqy7lTrb"
   },
   "source": [
    "If you’ve been following along for our question answering journey thus far, you now understand the basic building blocks that form the pipeline of a modern Information Retrieval-based (IR) Question Answering system, and how that system can be evaluated on the SQuAD2.0 dataset. But as it turns out, implementing question answering for real-world use cases is a bit more nuanced than evaluating system performance against a toy dataset. In this post, we’ll explore several challenges faced by the Retriever when applying IR-QA to a more realistic dataset, as well as a few practical approaches for overcoming them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "np9SZdgqBQ7m"
   },
   "source": [
    "### Prerequisites\n",
    "* a basic understanding of IR-QA systems (see our [previous posts](https://qa.fastforwardlabs.com/))\n",
    "* a basic understanding modern NLP techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pWWsT7nlTrc"
   },
   "source": [
    "# Shortcomings of SQuAD2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-q2l9AkZlTrd"
   },
   "source": [
    "While SQuAD has been a popular benchmark for the task of machine comprehension, there are several perceived flaws in how the dataset was constructed that renders it an unfair comparison to how humans naturally seek answers to questions. Specifically, SQuAD was created through artificial crowdsourcing where annotators were presented with a Wikipedia paragraph and asked to write questions that can be answered from it. This is a fundamentally different scenario than human curiosity blindly seeking answers to an unknown domain. By first reading a body of text and then generating questions, the annotators had already leaked information into the questions they crafted. The methodology used here is not ideal because a.) many questions lack context in absence of the provided paragraph and b.) there is a high lexical overlap between passages and questions - artificially inflating the efficacy of exact match search tools (like Elasticsearch). Consider the following example:\n",
    "\n",
    "> ***Question:*** Other than the Automobile Club of Southern California, what other AAA Auto Club chose to simplify the divide?\n",
    "<br>\n",
    "> ***Answer:*** California State Automobile Association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A More Realistic Alternative: Natural Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In response to the criticism of SQuAD’s shortcomings and to spur the progress of open-domain QA systems, Google released the [Natural Questions (NQ) dataset](https://ai.google.com/research/NaturalQuestions) in 2019. NQ consists of real, anonymized questions issued to the Google search engine and provides an entire Wikipedia article as context that may or may not contain the answer to a given question. The inclusion of open-ended, human-written questions and the need to reason over full pages of content make NQ a much more realistic and challenging task than datasets before it. Here are a few example questions from NQ:\n",
    "\n",
    "- where does the energy in a nuclear explosion come from?\n",
    "- how many episodes in season 2 breaking bad?\n",
    "- meaning of cats in the cradle song?\n",
    "\n",
    "Notice how some NQ questions are underspecified, raw, and syntactically erroneous? Do these seem oddly familiar to how you interact with search engines everyday? Let’s explore a couple of techniques that might help overcome the challenges presented by this dataset and improve the Elasticsearch Retriever we built in the previous blog post.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Expansion Techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned from the last blog post, the inverted index data structure underlying Elasticsearch doesn’t preserve word order in a query by default. Consider the following question:\n",
    "\n",
    "> ***Question:*** \"Who is the bad guy in The Hunger Games?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we as humans can intuit that the combination of words “The Hunger Games” has a very specific meaning in contrast to the three tokens independently. We want to enable Elasticsearch to identify content specific to the \"Hunger Games” trilogy, and not become entangled with general content about hunger and games. To accomplish this, we can apply named entity recognition (NER) - an information extraction technique that automatically identifies named entities (e.g. people, places, organizations, locations, etc.) in free text. \n",
    "\n",
    "Implementing entity enrichment requires extended use of Elasticsearch’s [rich query language](https://elasticsearch-dsl.readthedocs.io/en/latest/) and a pre-trained NER model (we chose one readily available through the [spaCy](https://spacy.io/) NLP library). The process is as follows:\n",
    "1. Apply NER to process a question and extract out any named entities\n",
    "2. Create a phrase sub-query for each entity to preserve the order of tokens for that phrase in match criteria\n",
    "3. Create a standard match sub-query for the original question itself\n",
    "4. Combine all sub-queries into a boolean compound query that scores candidate documents according to overlap criteria from both question and phrase queries\n",
    "\n",
    "To simplify query expansion testing, we built a QueryExpander class (hidden below) that automates several query expansion methods. Let's take a look how our query is transformed through entity enrichment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "\n",
    "# install dependencies\n",
    "!pip install elasticsearch_dsl\n",
    "!pip install transformers==2.11.0\n",
    "\n",
    "# import packages\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import spacy\n",
    "from elasticsearch_dsl import Q, Search\n",
    "import gensim.downloader as api\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# initialize models\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-50\")\n",
    "unmasker = pipeline('fill-mask', model=\"bert-base-uncased\", tokenizer=\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
    "\n",
    "class QueryExpander:\n",
    "    '''\n",
    "    Query expansion utility class that augments an ElasticSearch query with optional techniques\n",
    "    including Named Entity Recognition and Synonym Expansion\n",
    "    \n",
    "    Args:\n",
    "        question_text\n",
    "        entity_args (dict) - Ex. {'spacy_model': nlp}\n",
    "        synonym_args (dict) - Ex. {'gensim_model': word_vectors, 'n_syns': 3} OR\n",
    "                                  {'MLM': unmasker, 'tokenizer': base_tokenizer, 'n_syns': 3, 'threshold':0.3}\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, question_text, entity_args=None, synonym_args=None):\n",
    "        \n",
    "        self.question_text = question_text\n",
    "        self.entity_args = entity_args\n",
    "        self.synonym_args = synonym_args\n",
    "\n",
    "        if self.synonym_args and not self.entity_args:\n",
    "            raise Exception('Cannot do synonym expansion without NER! Expanding synonyms\\\n",
    "                            on named entities reduces recall.')\n",
    "\n",
    "        if self.synonym_args or self.entity_args:\n",
    "            self.nlp = self.entity_args['spacy_model']\n",
    "            self.doc = self.nlp(self.question_text)\n",
    "        \n",
    "        self.build_query()\n",
    "        \n",
    "    def build_query(self):\n",
    "\n",
    "        # build entity sub-query\n",
    "        if self.entity_args:\n",
    "            self.extract_entities()\n",
    "        \n",
    "        # identify terms to expand\n",
    "        if self.synonym_args:\n",
    "            self.identify_terms_to_expand()\n",
    "        \n",
    "        # build question sub-query\n",
    "        self.construct_question_query()\n",
    "        \n",
    "        # combine sub-queries\n",
    "        sub_queries = []\n",
    "        sub_queries.append(self.question_sub_query)\n",
    "        if hasattr(self, 'entity_sub_queries'):\n",
    "            sub_queries.extend(self.entity_sub_queries)\n",
    "            \n",
    "        query = Q('bool', should=[*sub_queries])\n",
    "        self.query = query\n",
    "        \n",
    "    \n",
    "    def extract_entities(self):\n",
    "        '''\n",
    "        Extracts named entities using spaCy and constructs phrase match sub-queries\n",
    "        for each entity. Saves both entities and sub-queries as attributes.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        entity_list = [entity.text.lower() for entity in self.doc.ents]\n",
    "        # print('Entities:', entity_list)\n",
    "        \n",
    "        entity_sub_queries = []\n",
    "        \n",
    "        for ent in entity_list:\n",
    "            eq = Q('multi_match',\n",
    "                   query=ent,\n",
    "                   type='phrase',\n",
    "                   fields=['title', 'text'])\n",
    "            \n",
    "            entity_sub_queries.append(eq)\n",
    "        \n",
    "        self.entities = entity_list\n",
    "        self.entity_sub_queries = entity_sub_queries\n",
    "        \n",
    "        \n",
    "    def identify_terms_to_expand(self):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        if hasattr(self, 'entities'):\n",
    "            # get unique list of entity tokens\n",
    "            entity_terms = [ent.split(' ') for ent in self.entities]\n",
    "            entity_terms = [ent for sublist in entity_terms for ent in sublist]\n",
    "        else:\n",
    "            entity_terms = []\n",
    "    \n",
    "        # terms to expand are that not part of entity or a stopword\n",
    "        entity_pos = [\"NOUN\",\"VERB\",\"ADJ\",\"ADV\"]\n",
    "        terms_to_expand = [idx_term for idx_term in enumerate(self.doc) if \\\n",
    "                           (idx_term[1].lower_ not in entity_terms) and (not idx_term[1].is_stop)\\\n",
    "                            and (not idx_term[1].is_digit) and (not idx_term[1].is_punct) and \n",
    "                            (not len(idx_term[1].lower_)==1 and idx_term[1].is_alpha) and\n",
    "                            (idx_term[1].pos_ in entity_pos)]\n",
    "        \n",
    "        self.terms_to_expand = terms_to_expand\n",
    "\n",
    "        \n",
    "    def construct_question_query(self):\n",
    "        '''\n",
    "        Builds a multi-match query from the raw question text extended with synonyms \n",
    "        for eligible any terms (i.e. terms that are not part of an entity or stopword)\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if hasattr(self, 'terms_to_expand'):\n",
    "            # print(self.question_text)\n",
    "            \n",
    "            syns = []\n",
    "            for i, term in self.terms_to_expand:\n",
    "\n",
    "                if 'gensim_model' in self.synonym_args.keys():\n",
    "                    syns.extend(self.gather_synonyms_static(term))\n",
    "                    # print('Static:', term, '-->', self.gather_synonyms_static(term))\n",
    "\n",
    "                elif 'MLM' in self.synonym_args.keys():\n",
    "                    syns.extend(self.gather_synonyms_contextual(i, term))\n",
    "                    # print('Contextual:', term, '-->', self.gather_synonyms_contextual(i,term))\n",
    "\n",
    "            syns = list(set(syns))\n",
    "            syns = [syn for syn in syns if (syn.isalpha() and self.nlp(syn)[0].pos_ != 'PROPN')]\n",
    "            # print('\\n', 'Final Terms:', syns)\n",
    "            \n",
    "            question = self.question_text + ' ' + ' '.join(syns)\n",
    "            self.expanded_question = question\n",
    "            self.all_syns = syns\n",
    "        \n",
    "        else:\n",
    "            question = self.question_text\n",
    "        \n",
    "        qq = Q('multi_match',\n",
    "               query=question,\n",
    "               type='most_fields',\n",
    "               fields=['title', 'text'])\n",
    "        \n",
    "        self.question_sub_query = qq\n",
    "\n",
    "\n",
    "    def gather_synonyms_contextual(self, token_index, token):\n",
    "        '''\n",
    "        Takes in a token, and returns specified number of synonyms as defined by\n",
    "        predictions from a Masked Language Model.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        tokens = [token.text for token in self.doc]\n",
    "        tokens[token_index] = self.synonym_args['tokenizer'].mask_token\n",
    "        \n",
    "        terms = self.predict_mask(text = ' '.join(tokens), \n",
    "                                    unmasker = self.synonym_args['MLM'],\n",
    "                                    tokenizer = self.synonym_args['tokenizer'],\n",
    "                                    threshold = self.synonym_args['threshold'],\n",
    "                                    top_n = self.synonym_args['n_syns'])\n",
    "        \n",
    "        return terms\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_mask(text, unmasker, tokenizer, threshold=0, top_n=2):\n",
    "        '''\n",
    "        Given a sentence with a [MASK] token in it, this function will return the most \n",
    "        contextually similar terms to fill in the [MASK]\n",
    "        \n",
    "        '''\n",
    "\n",
    "        preds = unmasker(text)\n",
    "        tokens = [tokenizer.convert_ids_to_tokens(pred['token']) for pred in preds if pred['score'] > threshold]\n",
    "        \n",
    "        return tokens[:top_n]\n",
    "        \n",
    "\n",
    "    def gather_synonyms_static(self, token):\n",
    "        '''\n",
    "        Takes in a token and returns a specified number of synonyms defined by\n",
    "        cosine similarity of word vectors. Uses stemming to ensure none of the\n",
    "        returned synonymns share the same stem (ex. photo and photos cant happen)\n",
    "        \n",
    "        '''\n",
    "        try:\n",
    "            syns = self.synonym_args['gensim_model'].similar_by_word(token.lower_)\n",
    "\n",
    "            lemmas = []\n",
    "            final_terms = []\n",
    "            for item in syns:\n",
    "                term = item[0]\n",
    "                lemma = self.nlp(term)[0].lemma_\n",
    "\n",
    "                if lemma in lemmas:\n",
    "                    continue\n",
    "                else:\n",
    "                    lemmas.append(lemma)\n",
    "                    final_terms.append(term)\n",
    "                    if len(final_terms) == self.synonym_args['n_syns']:\n",
    "                        break\n",
    "        except:\n",
    "            final_terms = []\n",
    "\n",
    "        return final_terms\n",
    "\n",
    "    def explain_expansion(self, entities=True):\n",
    "        \n",
    "        print('Question:', self.question_text, '\\n')\n",
    "        \n",
    "        if entities:\n",
    "            print('Found Entities:', self.entities, '\\n')\n",
    "        \n",
    "        if hasattr(self, 'terms_to_expand'):\n",
    "            \n",
    "            print('Synonym Expansions:')\n",
    "        \n",
    "            for i, term in self.terms_to_expand:\n",
    "                \n",
    "                if 'gensim_model' in self.synonym_args.keys():\n",
    "                    print(term, '-->', self.gather_synonyms_static(term))\n",
    "                \n",
    "                elif 'MLM' in self.synonym_args.keys():\n",
    "                    print(term, '-->', self.gather_synonyms_contextual(i,term))\n",
    "            \n",
    "                else:\n",
    "                    print('Question text has no terms to expand.')\n",
    "                    \n",
    "            print()\n",
    "            print('Expanded Question:', self.expanded_question, '\\n')\n",
    "        \n",
    "        print('Elasticsearch Query:\\n', self.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the bad guy in The Hunger Games? \n",
      "\n",
      "Found Entities: ['the hunger games'] \n",
      "\n",
      "Elasticsearch Query:\n",
      " Bool(should=[MultiMatch(fields=['title', 'text'], query='Who is the bad guy in The Hunger Games?', type='most_fields'), MultiMatch(fields=['title', 'text'], query='the hunger games', type='phrase')])\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is the bad guy in The Hunger Games?\"\n",
    "\n",
    "entity_args = {'spacy_model': nlp}\n",
    "\n",
    "qe_ner = QueryExpander(question, entity_args)\n",
    "qe_ner.explain_expansion(entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the example above, we see that our NER model successfully identified \"The Hunger Games\" as a named entity, and the final boolean query served to Elasticsearch is comprised of two parts: one multi-match query for the raw question text, and one phrase-match query for the extracted entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonym Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact match nature of Elasticsearch is powerful and effective, but isn't perfect. Word matching is limited in its ability to take semantically related concepts into consideration, and for the vague nature of NQ questions, will degrade the performance of our Retriever. For example, let's further consider the question from above and a supporting context passage:\n",
    "\n",
    "> ***Question:*** \"Who is the bad guy in The Hunger Games?\"\n",
    "<br>\n",
    "> ***Context:*** \"President Coriolanus Snow is the main antagonistic villain in The Hunger Games trilogy, and though seemingly laid-back, his demeanor hides a sadistic mind.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An exact-match based Retriever like Elasticsearch would struggle to fetch this supporting context passage because it lacks the ability to relate the concepts of \"bad guy\" and \"villain\". More [sophisticated document retrieval systems](https://arxiv.org/pdf/2004.04906.pdf) that take advantage of learned, dense representations of text would perform better in this situation, however these systems are non-trivial to implement and impractical to maintain. Rather, we can try to help generalize the query through synonym expansion at search time - that is, identify ambiguous terms in the input question and augment the query with additional synonyms for those terms. But how do we determine what a synonym is? And how do we know which terms in the question should be expanded?\n",
    "\n",
    "We experimented with two methods that follow the same process, but differ slightly in how synonyms are designated. The process entails:\n",
    "\n",
    "1. **Identifying a set of candidate tokens.**  Ideally, we want to expand tokens such that additional terms serve to increase recall while adding minimal noise or altering the semantics of the original query. We look at every term in the question and choose to only expand nouns, verbs, adjectives, and adverbs that are not part of a named entity.\n",
    "2. **Expanding each candidate token.** Related terms can be derived in numerous ways from traditional lexicon lookups (e.g. WordNet) to similarity measures between learned vector space representations (e.g. Word2Vec). We’ve tested out the use of static word embedding similarity and masked language model predictions as proxies for generating synonymous terms (more on these methods in a bit).\n",
    "3. **Post-processing synonyms and crafting a new query.** We then filter the expanded vocabulary to remove any duplicative, non-alphanumeric, or proper noun tokens. The final set of expanded terms is used to create a new Elasticsearch query by appending the novel words to the original question text.\n",
    "\n",
    "Let’s dive deeper into the two expansion methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Embedding Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are real-valued, vector representations of text that capture general contextual similarities between words in a given vocabulary. They are built on the idea that similar words tend to occur together frequently and thus are learned in an unsupervised manner from vast amounts of unstructured text. Their numerical form allows for mathematical operations - a common application being vector similarity. Since the vectors have been trained to represent the natural co-occurance of words, we extrapolate that terms corresponding to vectors with high cosine similarity are contextually synonomous. These word relationships are learned with regard to the data they are trained on, so it is critical that the training corpus for a set of embeddings is indicative of the downstream task the embedding vectors will be applied to. For that reason, we make use of 100 length [GloVe](https://nlp.stanford.edu/pubs/glove.pdf) word vectors trained on Wikipedia and made available through the [Gensim library](https://radimrehurek.com/gensim/). \n",
    "\n",
    "Let's take a look at an example question and how it is expanded using static embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is Thomas Middleditch's popular tv show? \n",
      "\n",
      "Found Entities: [\"thomas middleditch's\"] \n",
      "\n",
      "Synonym Expansions:\n",
      "popular --> ['famous', 'most']\n",
      "tv --> ['television', 'broadcast']\n",
      "\n",
      "Expanded Question: what is Thomas Middleditch's popular tv show? broadcast famous television most \n",
      "\n",
      "Elasticsearch Query:\n",
      " Bool(should=[MultiMatch(fields=['title', 'text'], query=\"what is Thomas Middleditch's popular tv show? broadcast famous television most\", type='most_fields'), MultiMatch(fields=['title', 'text'], query=\"thomas middleditch's\", type='phrase')])\n"
     ]
    }
   ],
   "source": [
    "question = \"what is Thomas Middleditch's popular tv show?\"\n",
    "\n",
    "entity_args = {'spacy_model': nlp}\n",
    "synonym_args = {'gensim_model': word_vectors,\n",
    "                'n_syns': 2}\n",
    "\n",
    "qe_static = QueryExpander(question, entity_args, synonym_args)\n",
    "qe_static.explain_expansion(entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we notice that \"popular\" and \"tv\" were the only tokens from the question deemed as candidates for expansion because all others are either stopwords or proper nouns composing a named entity. The expansion terms generated from our embedding similarity technique appear to be synonyms to the candidate terms, and by expanding the question with these related terms, we help generalize the query to capture a wider range of potentially relevant content. However, while this example demonstrates a (mostly) successful use of embedding similarity, this is not always the case..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the semantic value baked into word embeddings, there are several limitations to their use as a proxy for synonomous meaning. Let's look at another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: how many rose species are found in the Montreal Botanical Garden? \n",
      "\n",
      "Found Entities: ['montreal botanical garden'] \n",
      "\n",
      "Synonym Expansions:\n",
      "rose --> ['fell', 'climbed']\n",
      "species --> ['genus', 'subspecies']\n",
      "found --> ['discovered', 'identified']\n",
      "\n",
      "Expanded Question: how many rose species are found in the Montreal Botanical Garden? subspecies identified climbed discovered fell genus \n",
      "\n",
      "Elasticsearch Query:\n",
      " Bool(should=[MultiMatch(fields=['title', 'text'], query='how many rose species are found in the Montreal Botanical Garden? subspecies identified climbed discovered fell genus', type='most_fields'), MultiMatch(fields=['title', 'text'], query='montreal botanical garden', type='phrase')])\n"
     ]
    }
   ],
   "source": [
    "question = \"how many rose species are found in the Montreal Botanical Garden?\"\n",
    "\n",
    "qe_static = QueryExpander(question, entity_args, synonym_args)\n",
    "qe_static.explain_expansion(entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After drawing your attention to the suggested expansions for the term \"rose\", it is obvious that our approach lacks the ability to disambiguate between different senses of the same word. As humans, we naturally infer that the term \"rose\" implies a flower rather than the past-tense action of ascending from a lower position to a higher one. This illustrates a main limitation of word embeddings - words with multiple meanings are conflated into a single, static representation. In linguistic terms, polysemy and homonymy are not handled effectively.\n",
    "\n",
    "Not only have we altered the semantics of the original query by introducing the new terms for the *wrong* word-sense, but our approach has also failed to accurately capture synonomous terms for that mistaken word-sense. We see that \"rose\" expanded to \"fell\" and \"climbed\"...the first of which is actually an antonym. What is going on here? As mentioned earlier, word embeddings are trained at the task of modeling co-occurance probabilities. So while terms that occur in similar contexts *may sometimes* be synonomous, that certainly is not always the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Query Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was missing from the prior approach that allows us as humans to disambiguate the meaning of the word \"rose\"? The answer is *context*. The ability to dynamically recognize alternate meaning by paying attention to the context surrounding a term allows us to de-conflate homonymns. For a computer to do the same, we can make use of a masked language model (MLM) to leverage the bi-directional context surrounding a given word and imply its morphological form.\n",
    "\n",
    "> Note: For more info how a masked language model works, we recommend the original [BERT paper](https://arxiv.org/pdf/1810.04805.pdf) and this [interactive tool from AllenNLP](https://demo.allennlp.org/masked-lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, this involves constructing intermediate versions of the original question where each identified candidate token is masked, and a MLM predicts the top N tokens that are contextually most likely to complete the sentence. As with static embeddings, contextual query expansion relies on the assumption that the MLM has been trained (or fine-tuned) on the target document corpus so it holds relevant, implicit information that can be exploited to identify suitable expansion terms. \n",
    "\n",
    "In our case, we make use of a *BERT-base-uncased* model that has also been pre-trained on Wikipedia and made conveniently available through [HuggingFace's](https://huggingface.co/) \"fill-mask\" pipeline API. Let's see how this approach performs on our ambiguous example from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: how many rose species are found in the Montreal Botanical Garden? \n",
      "\n",
      "Found Entities: ['montreal botanical garden'] \n",
      "\n",
      "Synonym Expansions:\n",
      "rose --> ['plant', 'new']\n",
      "species --> ['varieties', 'gardens']\n",
      "found --> ['grown', 'found']\n",
      "\n",
      "Expanded Question: how many rose species are found in the Montreal Botanical Garden? varieties grown found new gardens plant \n",
      "\n",
      "Elasticsearch Query:\n",
      " Bool(should=[MultiMatch(fields=['title', 'text'], query='how many rose species are found in the Montreal Botanical Garden? varieties grown found new gardens plant', type='most_fields'), MultiMatch(fields=['title', 'text'], query='montreal botanical garden', type='phrase')])\n"
     ]
    }
   ],
   "source": [
    "question = \"how many rose species are found in the Montreal Botanical Garden?\"\n",
    "entity_args = {'spacy_model': nlp}\n",
    "synonym_args = {'MLM': unmasker, \n",
    "                'tokenizer': tokenizer, \n",
    "                'n_syns': 2,\n",
    "                'threshold':0}\n",
    "\n",
    "qe_contextual = QueryExpander(question, entity_args, synonym_args)\n",
    "qe_contextual.explain_expansion(entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Because we are now using supervised model to consider the full sentence and predict the missing candidate terms, we are able to capture the correct meaning of the term \"rose\" and also produce more reliable \"synonyms\" for each of the three expanded terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Query Expansion Improve Retrieval on Natural Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the topical breadth of Natural Questions, a vast knowledge base is needed for the Retriever to search over in order to fairly evaluate an end-to-end QA system. For that reason, a full Wikipedia dump was [cleaned](https://github.com/attardi/wikiextractor) and loaded into an Elasticsearch index for testing. To represent a practical application of QA, full articles were indexed rather than pre-parsed paragraphs (as we saw in the previous post). The [NQ development set](https://ai.google.com/research/NaturalQuestions/download) was processed to drop all long and yes/no answer questions, yielding 7651 short and null answer examples. Additionally, answers with more than 5 tokens were discarded as answers with many tokens often resemble extractive snippets rather than canonical answers.\n",
    "\n",
    "With our knowledge corpus and evaluation data ready to go, we evaluated Retriever performance (with the same methodology used in the last post) over an increasing number of documents while toggling entity and synonym expansion methods at search time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/post_arr/expansion_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, we see that returning more articles increases Retriever recall because there exists more content that may contain a question’s answer. However, that performance gain begins to plateau as additional content becomes less relevant to the query. We observe a performance plateau occurs at ~70% recall when retrieving 14 full Wikipedia articles. Despite the differences in experimental setup, when we compare that to the ~83% recall on SQuAD from the last post (when retrieving only 3 *paragraphs* of content), it becomes evident just how much more challenging the NQ dataset actually is. We also observe that entity expansion provides in a slight improvement to recall as it increases specificity of the query definition to help target multi-word phrases in articles.\n",
    "\n",
    "Finally, we observe a loss in performance when expanding candidate question terms with synonyms from either proposed method. What is going on here? While the intuition behind synonym expansion makes sense in theory, we ultimately find it very difficult to implement a \"one-size-fits-all\" approach for determining relevant synonyms. Even after adding a probability threshold for MLM expansion term predictions to further minimize the chance of introducing spurious terms, we are unable to consistently filter out noise. Qualitative analysis reveals that expansion does work in some cases, but also over-generalizes in others. In the world of information retrieval, relevancy tuning is a deeply complex subject and requires customization for each use case. Therefore it is generally not recommended to apply blanket synonym expansion techniques. Rather, using search-time expansion of similar terms from a curated ontology or acronym lookup specific to your domain may be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passage Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from our last post that in an IR QA system, the Reader is bounded by the performance of the Retriever, and fetching more documents increases system recall. However, simply increasing the number of documents passed to the Reader also increases the amount of irrelevant information that is processed and degrades the overall QA system performance - both speed and accuracy. But what if we could have the best of both worlds?\n",
    "\n",
    "Passage ranking is a technique that involves selecting a subset of re-ranked paragraphs from a collection of retrieved documents to retain the answer recall from those documents, while filtering out noisy content. By implementing a quick and efficient passage ranking technique, our QA pipeline considers more documents worth of information, but distills down only the relevant pieces for the Reader to process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/post_arr/passage_ranking_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of passage ranking is inspired by a field of information retrieval called *Learning to Rank* which frames relevance ranking as a supervised machine learning problem. While many [supervised ranking approaches](https://www.aclweb.org/anthology/D18-1053.pdf) have proven successful, they require learning custom similarity metrics and introduce additional complexity into a QA system - making them impractical for many use cases. In contrast, the passage ranking implementation that we consider here is a simple, unsupervised approach that demonstrates a viable way to improve IR for general question answering applications. Our passage ranking process consists of the following steps at search time:\n",
    "\n",
    "1. The query question and a set of N candidate documents from Elasticsearch are fed as input\n",
    "2. All documents are split into paragraphs\n",
    "3. The list of paragraphs and the input question are converted into a sparse document-term matrix (DTM) using TF-IDF vectorization. We preserve n-grams during vectorization, so the final DTM includes single terms, bi-grams, and tri-grams.\n",
    "4. Cosine similarity is calculated between the question vector and each paragraph vector\n",
    "5. Paragraphs are sorted based on similarity score and the top M passages are passed on to the Reader for answer extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include hidden code of Passage Ranker here? It won't be functional withough elastic search setup..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Passage Ranking Improve Retrieval on Natural Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the effect of passage ranking, we evaluated system recall across the NQ development set while retrieving one article’s worth of content as determined from two different methods:\n",
    "- The top 1 article scored and returned directly from Elasticsearch\n",
    "- The top 20 ranked passages pooled from N candidate documents\n",
    "\n",
    "A fair comparison between techniques requires consideration of an equal amount of retrieved content. We found Wikipedia articles corresponding to our NQ development set contain 20 paragraphs on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/post_arr/passage_ranking_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experimental results support the notion that introducing an intermediate passage ranking step into the QA pipeline allows us to improve system recall by almost 10 percentage points for a fixed amount of context. We notice that system recall increases to 53.3% as the number of candidate documents that content is pooled from increases - up until ~7 documents, then it slowly decreases. This demonstrates that after 7 documents worth of content, our sparse vector ranking algorithm loses signal as additional unrelated noise is introduced to the ranking corpus.\n",
    "\n",
    "We also evaluate the time complexity of the passage ranking process and notice that the peak recall (@7 documents of content) comes at a cost of 6x processing time (compared to retrieving 1 document from Elasticsearch). While this appears considerable, it's important to frame this cost in the setting of the full QA pipeline. Passage ranking enables our already slow Reader to only process 1/7th the amount of content while providing 20% more answers in the context window for the price of 0.1 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, we identified a few challenges in applying IR QA systems to a more realistic QA task, and we looked a variety of techniques to help improve information retrieval. In the end, we found that entity expansion and passage ranking prove successful in returning more answer-containing context for the Reader to extract answers from. Additionally, we learned that while contextual synonym expansion may help Elasticsearch in some instances, it cannot be used as a blanket approach for relevancy tuning. In our final blog post we'll explore how transfer learning can help boost Reader performance on a domain specific dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('/Users/areed/opt/anaconda3/envs/qa-blog/lib/python3.7/site-packages')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "In0YUapuBQ8A",
    "pKVJVU5hBQ8U",
    "t4s4Bx3LBQ8p"
   ],
   "machine_shape": "hm",
   "name": "2020-06-09-Evaluating_BERT_on_SQuAD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f9413092ffe496d8f31c374732e870d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "139cd5c5c43f436495dfddbdfc7d35c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15f44b8cf87d459bb6a40b5e6b9db470": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26b9259fecf4445b8fdcb753ed6d09ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "26ef4a7e1f76465ead7e51c1d9866c6f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28a305d13e584615b9ba3cd9a37bdd56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8cebe4ccf004d84bdc37ce44d1192e8",
      "max": 20239,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a44c2693aee14b89a4c6512c85142f51",
      "value": 20239
     }
    },
    "3c0ffe3eeca741899ddbe1306e60ce39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26ef4a7e1f76465ead7e51c1d9866c6f",
      "placeholder": "​",
      "style": "IPY_MODEL_7a1bbfb20bd84d4b8995584a37dabae1",
      "value": " 11873/11873 [6:21:18&lt;00:00,  1.93s/it]"
     }
    },
    "3d3ce5e897b84a218237582372bca2bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40b3ea36c5ca407597e8ce6c738c9786": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "62fb51c849b04bc78c629dd42f811deb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f9413092ffe496d8f31c374732e870d",
      "placeholder": "​",
      "style": "IPY_MODEL_3d3ce5e897b84a218237582372bca2bb",
      "value": " 11873/11873 [7:01:01&lt;00:00,  2.13s/it]"
     }
    },
    "66e0efa9685248629e009c1e255bff6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6c75626f2d54bfbaa7bad761af5b9c2",
       "IPY_MODEL_62fb51c849b04bc78c629dd42f811deb"
      ],
      "layout": "IPY_MODEL_f0858954bbfd447eb95a04a3caabf8a4"
     }
    },
    "705fa1214c044cbcae6f5d109b22802d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f04b80c35efb44b5bec078f4d7a57f3b",
      "max": 11873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e30ff795eb1c4016be3967f190764399",
      "value": 11873
     }
    },
    "7a1bbfb20bd84d4b8995584a37dabae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9061d4497e4443029cbb21b77281cf31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95923a713e324d18bc9fc82a466703c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef2c1a3506c549b7878e3ea4a5cc565f",
      "placeholder": "​",
      "style": "IPY_MODEL_139cd5c5c43f436495dfddbdfc7d35c3",
      "value": " 20239/20239 [02:38&lt;00:00, 127.56it/s]"
     }
    },
    "a299f8fa902348b7807b4d97ebc6027d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dca5b0a8c1014a66bc8c5ba988878a85",
      "placeholder": "​",
      "style": "IPY_MODEL_b04d963baf9a40789305d1372ffe1aab",
      "value": " 20239/20239 [04:14&lt;00:00, 79.57it/s]"
     }
    },
    "a44c2693aee14b89a4c6512c85142f51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a493a4c07a2743899571330cf6476b74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28a305d13e584615b9ba3cd9a37bdd56",
       "IPY_MODEL_a299f8fa902348b7807b4d97ebc6027d"
      ],
      "layout": "IPY_MODEL_e94a6f98578743c096c9b045d9dfdf81"
     }
    },
    "a8cebe4ccf004d84bdc37ce44d1192e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b04d963baf9a40789305d1372ffe1aab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be3cf3e6c6ba40d087f8dd27dd4f5e64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_705fa1214c044cbcae6f5d109b22802d",
       "IPY_MODEL_3c0ffe3eeca741899ddbe1306e60ce39"
      ],
      "layout": "IPY_MODEL_d193d10e1ad94119a849d123c093f3cc"
     }
    },
    "d193d10e1ad94119a849d123c093f3cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dca5b0a8c1014a66bc8c5ba988878a85": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e30ff795eb1c4016be3967f190764399": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e91c7ba9a6314f0d905d08d0f822cbc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e94a6f98578743c096c9b045d9dfdf81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef2c1a3506c549b7878e3ea4a5cc565f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f04b80c35efb44b5bec078f4d7a57f3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0858954bbfd447eb95a04a3caabf8a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4d90214c67749168472a2ba3cb0d72a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9061d4497e4443029cbb21b77281cf31",
      "max": 20239,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40b3ea36c5ca407597e8ce6c738c9786",
      "value": 20239
     }
    },
    "f6c75626f2d54bfbaa7bad761af5b9c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e91c7ba9a6314f0d905d08d0f822cbc1",
      "max": 11873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26b9259fecf4445b8fdcb753ed6d09ef",
      "value": 11873
     }
    },
    "f8d18feb30b24de5bbbb869cc9a31ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4d90214c67749168472a2ba3cb0d72a",
       "IPY_MODEL_95923a713e324d18bc9fc82a466703c4"
      ],
      "layout": "IPY_MODEL_15f44b8cf87d459bb6a40b5e6b9db470"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
